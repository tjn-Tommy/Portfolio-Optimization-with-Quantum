from typing import Callable, Optional, Sequence, Any, Dict

import numpy as np
from tqdm import tqdm
from qiskit import QuantumCircuit, transpile
from qiskit.circuit import ParameterVector
from scipy.optimize import minimize, OptimizeResult
from qiskit.quantum_info import SparsePauliOp
from optimizer.base import BaseOptimizer
from optimizer.utils.qubo_utils import compute_num_spins as compute_num_spins_optimized
from optimizer.utils.qubo_utils import spins_to_asset_counts
from optimizer.utils.qubo_utils import qubo_factor as qubo_factor_optimized
from optimizer.utils.qubo_utils import get_ising_coeffs as get_ising_coeffs_optimized
from optimizer.utils.qubo_utils import normalize_ising_coeffs
from optimizer.utils.noise_utils import build_aer_simulator
from qiskit_aer.primitives import EstimatorV2
import time

GRADIENT_BASED_METHODS = {
    "L-BFGS-B",
    "TNC",
    "SLSQP",
}
VALID_GRAD_METHODS = {"shot_based", "estimator"}


class QAOAOptimizer(BaseOptimizer):
    def __init__(
        self,
        lam: float,
        alpha: float,
        beta: Optional[float],
        bits_per_asset: int,
        bits_slack: int,
        transact_opt: str = "ignore",
        p: int = 1,
        shots: int = 1000,
        n_trials: int = 1,
        maxiter: int = 100,
        grad_delta: float = 0.01,
        init_spread: float = 0.0,
        seed: Optional[int] = None,
        optimization_algorithm: str = "COBYLA",
        grad_method: str = "shot_based",
        spsa_options: Optional[Dict[str, float]] = None,
        noise_config: Optional[Dict[str, Any]] = None,
        use_gpu: bool = False,
        use_history: bool = False,
        shift: float = 0.05,
    ):
        super().__init__(lam, beta)
        self.alpha = alpha
        self.bits_per_asset = bits_per_asset
        self.bits_slack = bits_slack
        self.transact_opt = transact_opt
        self.p = p
        self.shots = shots
        self.n_trials = n_trials
        self.maxiter = maxiter
        self.grad_delta = grad_delta
        self.init_spread = init_spread
        self.seed = seed
        self.optimization_algorithm = optimization_algorithm
        self.grad_method = grad_method
        self.spsa_options = spsa_options or {}
        self.noise_config = noise_config
        self.backend = build_aer_simulator(noise_config)
        if use_gpu:
            # 1. å¼ºåˆ¶ä½¿ç”¨ GPU
            self.backend.set_options(device='GPU')
            self.backend.set_options(precision='single', cuStateVec_enable=True) 

            
            print("âœ… GPU Acceleration enabled with Single Precision.")
        self.num_spins = 0
        self.estimator = EstimatorV2(
            options={
                
            "run_options":{"shots": None, "seed": 42},
            "backend_options":{
                "method": "statevector",      
                "device": "GPU" if use_gpu else "CPU",              
                "precision": "single",        
                "cuStateVec_enable": True,
            },}
            )
        self.use_history = use_history
        self.history = None
        self.shift = shift
        

    @classmethod
    def init(cls, cfg: Dict[str, Any], lam: float, beta: Optional[float]) -> "QAOAOptimizer":
        return cls(
            lam=lam,
            alpha=cfg["alpha"],
            beta=beta,
            transact_opt=cfg.get("transact_opt", "ignore"),
            bits_per_asset=cfg["bits_per_asset"],
            bits_slack=cfg["bits_slack"],
            p=cfg.get("p", 1),
            shots=cfg.get("shots", 1000),
            n_trials=cfg.get("n_trials", 1),
            maxiter=cfg.get("maxiter", 100),
            grad_delta=cfg.get("grad_delta", 0.01),
            init_spread=cfg.get("init_spread", 0.0),
            seed=cfg.get("seed"),
            optimization_algorithm=cfg.get(
                "optimization_algorithm",
                cfg.get("optimzation_algorithm", "COBYLA"),
            ),
            grad_method=cfg.get("grad_method", "shot_based"),
            spsa_options=cfg.get("spsa"),
            noise_config=cfg.get("noise"),
            use_gpu=cfg.get("use_gpu", False),
            use_history=cfg.get("use_history", False),
            shift=cfg.get("shift", 0.05),
        )

    def qubo_factor(
        self,
        n: int,
        mu: np.ndarray,
        sigma: np.ndarray,
        prices: np.ndarray,
        n_spins: int,
        budget: float,
        x0: Optional[np.ndarray] = None
    ):
        return qubo_factor_optimized(
            n=n,
            mu=mu,
            sigma=sigma,
            prices=prices,
            n_spins=n_spins,
            budget=budget,
            bits_per_asset=self.bits_per_asset,
            bits_slack=self.bits_slack,
            lam=self.lam,
            alpha=self.alpha,
            beta=self.beta,
            transact_opt=self.transact_opt,
            x0=x0,
        )

    def get_ising_coeffs(self, Q: np.ndarray, L: np.ndarray, constant: float):
        return get_ising_coeffs_optimized(Q, L, constant)
    
    def compute_num_spins(self,
                          n_assets: int,
                          x0: np.ndarray = None
    ):
        return compute_num_spins_optimized(
            n_assets=n_assets,
            bits_per_asset=self.bits_per_asset,
            bits_slack=self.bits_slack,
            transact_opt=self.transact_opt,
            x0=x0
        )
    
    def _spins_to_asset_counts(self,
               spins: np.ndarray,
               n_assets: int,
               x0: np.ndarray = None
    ):
        return spins_to_asset_counts(
            spins=spins,
            n_assets=n_assets,
            bits_per_asset=self.bits_per_asset,
            bits_plus=self.bits_plus,
            bits_minus=self.bits_minus,
            transact_opt=self.transact_opt,
            x0=x0
        )

    def _build_circuit(self, p: int, h: np.ndarray, J: np.ndarray, measure: bool=True) -> QuantumCircuit:
        betas = ParameterVector("betas", p)
        gammas = ParameterVector("gammas", p)
        qc = QuantumCircuit(self.num_spins)
        qc.h(range(self.num_spins))

        for layer in range(p):
            for i in range(self.num_spins):
                if h[i] != 0:
                    qc.rz(gammas[layer] * 2 * h[i], i)
            for i in range(self.num_spins):
                for j in range(i + 1, self.num_spins):
                    if J[i, j] != 0:
                        # qc.cx(i, j)
                        # qc.rz(gammas[layer] * 2 * J[i, j], j)
                        # qc.cx(i, j)
                        qc.rzz(gammas[layer] * 2 * J[i, j], i, j)
            for i in range(self.num_spins):
                qc.rx(betas[layer] * 2, i)
        if measure:
            qc.measure_all()
        return qc

    def _build_bind_dict(
        self,
        circ: QuantumCircuit,
        p: int,
        betas: np.ndarray,
        gammas: np.ndarray,
    ):
        param_map = {param.name: param for param in circ.parameters}
        bind_dict = {}
        for i in range(p):
            bind_dict[param_map[f"betas[{i}]"]] = [float(betas[i])]
            bind_dict[param_map[f"gammas[{i}]"]] = [float(gammas[i])]
        return bind_dict

    def _run_counts(
        self,
        circ: QuantumCircuit,
        bind_dict,
        shots: int,
    ):
        job = self.backend.run(circ, shots=shots, parameter_binds=[bind_dict])
        counts = job.result().get_counts()
        if isinstance(counts, list):
            return counts[0]
        return counts

    def _bitstring_to_spins(self, bitstring: str) -> np.ndarray:
        bits = bitstring.replace(" ", "")
        spins = np.empty(self.num_spins, dtype=int)
        for i, char in enumerate(reversed(bits)):
            spins[i] = 1 if char == "0" else -1
        return spins

    def _initial_params(
        self,
        p: int,
        initial_betas: Optional[Sequence[float]],
        initial_gammas: Optional[Sequence[float]],
    ) -> np.ndarray:
        if initial_betas is None:
            betas = 1 * np.linspace(1, 0, p)
        else:
            betas = np.asarray(initial_betas, dtype=float)
            if betas.size != p:
                raise ValueError("initial_betas must have length p")

        if initial_gammas is None:
            gammas = 1 * np.linspace(0, 1, p)
        else:
            gammas = np.asarray(initial_gammas, dtype=float)
            if gammas.size != p:
                raise ValueError("initial_gammas must have length p")

        return np.concatenate([betas, gammas])

    def _get_hamiltonian(self, h: np.ndarray, J: np.ndarray) -> SparsePauliOp:
        num_qubits = len(h)
        pauli_list = []
    
        for i, coeff in enumerate(h):
            if abs(coeff) > 1e-8:
                pauli_str = ["I"] * num_qubits
                pauli_str[num_qubits - 1 - i] = "Z" # Qiskit æ˜¯ Little Endianï¼Œç´¢å¼•è¦åè½¬
                pauli_list.append(("".join(pauli_str), coeff))
        
        rows, cols = np.nonzero(J)
        for i, j in zip(rows, cols):
            if i < j: 
                coeff = J[i, j]
                if abs(coeff) > 1e-8:
                    pauli_str = ["I"] * num_qubits
                    pauli_str[num_qubits - 1 - i] = "Z"
                    pauli_str[num_qubits - 1 - j] = "Z"
                    pauli_list.append(("".join(pauli_str), coeff))
        
        if not pauli_list:
            return SparsePauliOp(["I" * num_qubits], [0.0])
            
        return SparsePauliOp.from_list(pauli_list)

    # --- ä¼˜åŒ–ç‚¹ 1: å‘é‡åŒ–è®¡ç®—æœŸæœ›å€¼ (é€Ÿåº¦æå¤§æå‡) ---
    def _compute_expectation(
        self,
        counts: Dict[str, int],
        h: np.ndarray,
        J: np.ndarray,
    ) -> float:
        if not counts:
            return float("inf")
            
        # 1. æå–æ‰€æœ‰ bitstrings å’Œå¯¹åº”çš„é¢‘ç‡
        bitstrings = list(counts.keys())
        freqs = np.array(list(counts.values()), dtype=float)
        total_shots = np.sum(freqs)
        
        if total_shots <= 0:
            return float("inf")
            
        # 2. å‘é‡åŒ–è½¬æ¢ï¼šBitstring (str) -> Spins (numpy array)
        n_spins = len(h)
        
        # åˆ›å»ºå­—ç¬¦çŸ©é˜µ (M samples x N spins)
        # ä¾‹å¦‚ ['10', '01'] -> [['1','0'], ['0','1']]
        char_matrix = np.array([list(s) for s in bitstrings])
        
        # å°† '0'->1, '1'->-1ã€‚Qiskitè¾“å‡ºä¸­ '0'æ˜¯+1æ€, '1'æ˜¯-1æ€
        # æ³¨æ„ï¼šéœ€è¦åè½¬åˆ—é¡ºåºä»¥åŒ¹é…ä½ çš„ J çŸ©é˜µç´¢å¼•ï¼ˆé€šå¸¸ Qiskitè¾“å‡ºæ˜¯ qubit N...0ï¼‰
        # ä½ çš„åŸä»£ç ç”¨äº† reversed(bits)ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡ flip æ¨¡æ‹Ÿ
        spins_matrix = np.ones(char_matrix.shape, dtype=float)
        spins_matrix[char_matrix == '1'] = -1.0
        
        # å¦‚æœä½ çš„ qubit 0 å¯¹åº” bitstring çš„æœ€å³è¾¹ï¼ˆæ ‡å‡† Qiskitï¼‰ï¼Œåˆ™éœ€ç¿»è½¬çŸ©é˜µåˆ—
        spins_matrix = np.flip(spins_matrix, axis=1)

        # 3. å‘é‡åŒ–è®¡ç®—èƒ½é‡
        term1 = spins_matrix @ h
        term2 = np.sum((spins_matrix @ J) * spins_matrix, axis=1)
        energies = term1 + term2
        
        # 4. åŠ æƒå¹³å‡
        avg_energy = np.sum(energies * freqs) / total_shots
        return float(avg_energy)


    def _gradient_estimator(  # ä¿®æ­£æ‹¼å†™: gradiant -> gradient, estimater -> estimator
        self,
        x_init: np.ndarray,
        circ: QuantumCircuit,
        p: int,
        h: np.ndarray,
        J: np.ndarray,
        shots: int,
    ) -> np.ndarray:
        num_params = len(x_init)
        # start_time = time.time()
        # --- 1. æ„å»ºå‚æ•°çŸ©é˜µ (Batching) ---
        # æˆ‘ä»¬ä¸å†åˆ›å»º list of dictsï¼Œè€Œæ˜¯åˆ›å»ºä¸€ä¸ªå¤§çš„ numpy array
        # å½¢çŠ¶: (2 * num_params, num_params)
        batch_params = np.empty((2 * num_params, num_params))
        
        for i in range(num_params):
            # x + delta
            batch_params[2 * i] = x_init.copy()
            batch_params[2 * i, i] += self.grad_delta
            
            # x - delta
            batch_params[2 * i + 1] = x_init.copy()
            batch_params[2 * i + 1, i] -= self.grad_delta

        # --- 3. æ„å»ºå•ä¸€ PUB (Broadcasting) ---
        hamiltonian = self._get_hamiltonian(h, J)
        pub = (circ, hamiltonian, batch_params)
        
        # --- 4. ä¸€æ¬¡æ€§æ‰§è¡Œ ---
        job = self.estimator.run([pub]) 
        result = job.result()
        
        # --- 5. è·å–ç»“æœ ---
        evs = result[0].data.evs
        
        # --- 6. è®¡ç®—æ¢¯åº¦ ---
        gradients = (evs[0::2] - evs[1::2]) / (2.0 * self.grad_delta)
        # end_time = time.time()
        # print(f"Gradient computed in {end_time - start_time:.2f} seconds.")
        return gradients

    # --- ä¼˜åŒ–ç‚¹ 2: ç›®æ ‡å‡½æ•° ---
    def _objective(
        self,
        x_init: np.ndarray,
        circ: QuantumCircuit,
        p: int,
        h: np.ndarray,
        J: np.ndarray,
        shots: int,
    ) -> float:
        if self.grad_method == "estimator":
            hamiltonian = self._get_hamiltonian(h, J)
            pub = (circ, hamiltonian, x_init)
            job = self.estimator.run([pub])
            result = job.result()
            energy = result[0].data.evs
            if isinstance(energy, np.ndarray):
                return float(energy.item())         
            return float(energy)
        else:
             # Shot-based è¯„ä¼°
            betas = x_init[:p]
            gammas = x_init[p:]
            bind_dict = self._build_bind_dict(circ, p, betas, gammas)
            counts = self._run_counts(circ, bind_dict, shots)
            return self._compute_expectation(counts, h, J)
        
    def _evaluate_expectations(
        self,
        param_sets: Sequence[np.ndarray],
        circ: QuantumCircuit,
        p: int,
        h: np.ndarray,
        J: np.ndarray,
        shots: int,
    ) -> Sequence[float]:
        if not param_sets:
            return []

        binds = []
        for params in param_sets:
            betas = params[:p]
            gammas = params[p:]
            binds.append(self._build_bind_dict(circ, p, betas, gammas))

        circuits_to_run = [circ] * len(binds)
        job = self.backend.run(circuits_to_run, shots=shots, parameter_binds=binds)
        counts_list = job.result().get_counts()
        if not isinstance(counts_list, list):
            counts_list = [counts_list]

        return [self._compute_expectation(counts, h, J) for counts in counts_list]

    def _gradient(
        self,
        x_init: np.ndarray,
        circ: QuantumCircuit,
        p: int,
        h: np.ndarray,
        J: np.ndarray,
        shots: int,
    ) -> np.ndarray:
        step = float(self.grad_delta)
        if step <= 0:
            raise ValueError("grad_delta must be positive for finite_diff.")
        scale = 1.0 / (2.0 * step)

        param_sets = []
        for i in range(len(x_init)):
            x_plus = x_init.copy()
            x_plus[i] += step
            x_minus = x_init.copy()
            x_minus[i] -= step
            param_sets.append(x_plus)
            param_sets.append(x_minus)

        energies = self._evaluate_expectations(param_sets, circ, p, h, J, shots)
        gradients = np.zeros(len(x_init))
        for i in range(len(x_init)):
            gradients[i] = scale * (energies[2 * i] - energies[2 * i + 1])
        return gradients
    
    def _compute_val_and_grad(
        self,
        x_init: np.ndarray,
        circ: QuantumCircuit,
        p: int,
        h: np.ndarray,
        J: np.ndarray,
        shots: int,
    ):
        num_params = len(x_init)
        
        # --- 1. æ„å»ºè¶…å¤§ Batch (1 + 2 * num_params) ---
        total_circuits = 1 + 2 * num_params
        batch_params = np.empty((total_circuits, num_params))
        
        # å¡«å…¥åŸå§‹å‚æ•°
        batch_params[0] = x_init
        
        # å¡«å…¥æ¢¯åº¦å‚æ•°
        for i in range(num_params):
            # x + delta
            batch_params[1 + 2 * i] = x_init.copy()
            batch_params[1 + 2 * i, i] += self.grad_delta
            
            # x - delta
            batch_params[1 + 2 * i + 1] = x_init.copy()
            batch_params[1 + 2 * i + 1, i] -= self.grad_delta

        # --- 2. åªæœ‰ä¸€æ¬¡ GPU è°ƒç”¨ (Crucial!) ---
        # Qiskit Aer ä¼šå¹¶è¡Œè®¡ç®—è¿™ 81 ä¸ªç”µè·¯
        if self.grad_method == "estimator":
            hamiltonian = self._get_hamiltonian(h, J)
            pub = (circ, hamiltonian, batch_params) # å¹¿æ’­
            job = self.estimator.run([pub])
            result = job.result()
            evs = result[0].data.evs
            
            # --- 3. è§£æç»“æœ ---
            # ç›®æ ‡å‡½æ•°å€¼ (ç¬¬ 1 ä¸ªç»“æœ)
            objective_value = float(evs[0])
            
            # æ¢¯åº¦ (å‰©ä¸‹çš„ç»“æœ)
            grad_evs = evs[1:]
            gradients = (grad_evs[0::2] - grad_evs[1::2]) / (2.0 * self.grad_delta)
            
            return objective_value, gradients

        else:
            raise NotImplementedError("Merged execution is currently optimized for Estimator only.")
        

    @staticmethod
    def _algorithm_uses_gradient(method: str) -> bool:
        return method.strip().upper() in GRADIENT_BASED_METHODS

    def _optimize_spsa(
        self,
        objective_fn: Callable[[np.ndarray], float],
        x_init: np.ndarray,
        maxiter: int,
        rng: Optional[np.random.Generator],
    ) -> OptimizeResult:
        if rng is None:
            rng = np.random.default_rng()

        options = self.spsa_options
        a = float(options.get("a", 0.2))
        c = float(options.get("c", 0.1))
        alpha = float(options.get("alpha", 0.602))
        gamma = float(options.get("gamma", 0.101))
        A = float(options.get("A", max(1, maxiter // 10)))

        x = x_init.copy()
        best_x = x.copy()
        best_val = objective_fn(x)
        n_params = len(x)

        for k in range(maxiter):
            ak = a / ((k + 1 + A) ** alpha)
            ck = c / ((k + 1) ** gamma)
            delta = rng.choice([-1.0, 1.0], size=n_params)
            x_plus = x + ck * delta
            x_minus = x - ck * delta
            f_plus = objective_fn(x_plus)
            f_minus = objective_fn(x_minus)
            g_hat = (f_plus - f_minus) / (2.0 * ck) * delta
            x = x - ak * g_hat

            f_val = objective_fn(x)
            if f_val < best_val:
                best_val = f_val
                best_x = x.copy()

        return OptimizeResult(x=best_x, fun=best_val, nit=maxiter)
    
    def optimize(
        self,
        mu: np.ndarray,
        prices: np.ndarray,
        sigma: np.ndarray,
        budget: float,
        x0: Optional[np.ndarray] = None,
        p: Optional[int] = None,
        shots: Optional[int] = None,
        n_trials: Optional[int] = None,
        maxiter: Optional[int] = None,
        initial_betas: Optional[Sequence[float]] = None,
        initial_gammas: Optional[Sequence[float]] = None,
        init_spread: Optional[float] = None,
        seed: Optional[int] = None,
        optimization_algorithm: Optional[str] = None,
        grad_method: Optional[str] = None,
        **kwargs,
    ) -> Optional[np.ndarray]:
        return self._optimize_interp(
            mu,
            prices,
            sigma,
            budget,
            x0,
            p,
            shots,
            n_trials,
            maxiter,
            initial_betas,
            initial_gammas,
            init_spread,
            seed,
            optimization_algorithm,
            grad_method,
            **kwargs,
        )

    def _optimize(
        self,
        mu: np.ndarray,
        prices: np.ndarray,
        sigma: np.ndarray,
        budget: float,
        x0: Optional[np.ndarray] = None,
        p: Optional[int] = None,
        shots: Optional[int] = None,
        n_trials: Optional[int] = None,
        maxiter: Optional[int] = None,
        initial_betas: Optional[Sequence[float]] = None,
        initial_gammas: Optional[Sequence[float]] = None,
        init_spread: Optional[float] = None,
        seed: Optional[int] = None,
        optimization_algorithm: Optional[str] = None,
        grad_method: Optional[str] = None,
        **kwargs,
    ) -> Optional[np.ndarray]:
        n = len(mu)
        self.num_spins, self.bits_plus, self.bits_minus = self.compute_num_spins(n, x0)

        Q, L, constant = self.qubo_factor(n, mu, sigma, prices, self.num_spins, budget, x0)
        h, J, C = self.get_ising_coeffs(Q, L, constant)
        h, J, C= normalize_ising_coeffs(h, J, C)
        
        outer_pbar = kwargs.get("outer_pbar")

        # å‚æ•°è®¾ç½®
        chosen_p = p if p is not None else self.p
        chosen_shots = shots if shots is not None else self.shots
        chosen_trials = n_trials if n_trials is not None else self.n_trials
        chosen_maxiter = maxiter if maxiter is not None else self.maxiter
        chosen_spread = init_spread if init_spread is not None else self.init_spread
        chosen_seed = seed if seed is not None else self.seed
        chosen_algorithm = (
            optimization_algorithm
            if optimization_algorithm is not None
            else self.optimization_algorithm
        )
        bounds = [(0, 2*np.pi)] * (2 * chosen_p)
        if not chosen_algorithm:
            chosen_algorithm = "COBYLA"
        chosen_grad_method = grad_method if grad_method is not None else self.grad_method
        method_key = chosen_algorithm.strip().upper()
        use_spsa = method_key == "SPSA"
        requires_gradient = self._algorithm_uses_gradient(method_key)
        grad_method_key = (chosen_grad_method or "").lower()
        if requires_gradient and grad_method_key not in VALID_GRAD_METHODS:
            raise ValueError(
                f"Unsupported grad_method: {chosen_grad_method}. "
                f"Choose from {sorted(VALID_GRAD_METHODS)}."
            )
        
        # æ„å»ºç”µè·¯
        circuit = self._build_circuit(chosen_p, h, J) 
        circuit_no_measure = self._build_circuit(chosen_p, h, J, measure=False)
        circuit = transpile(circuit, self.backend)
        circuit_no_measure = transpile(circuit_no_measure, self.backend)
        if self.use_history and self.history is not None:
            initial_betas = self.history.get("betas", initial_betas)
            initial_gammas = self.history.get("gammas", initial_gammas)
            # add gussian noise around previous best
            if initial_betas is not None:
                initial_betas = np.array(initial_betas) + np.random.normal(
                    scale=self.shift, size=chosen_p
                )
            if initial_gammas is not None:
                initial_gammas = np.array(initial_gammas) + np.random.normal(
                    scale=self.shift, size=chosen_p
                )
        base_params = self._initial_params(chosen_p, initial_betas, initial_gammas)
        rng = np.random.default_rng(chosen_seed)
        best_solution = None
        best_value = float("inf")
        obj_circuit = circuit_no_measure if grad_method_key == "estimator" else circuit
        objective_fn = lambda params: self._objective(
            params, obj_circuit
            , chosen_p, h, J, chosen_shots
        )
        objective_fn_with_grad = lambda params: self._compute_val_and_grad(
            params, obj_circuit, chosen_p, h, J, chosen_shots
        )

        total_iterations = 0
        metadata = kwargs.get("metadata", {})

        for trial in range(chosen_trials):
            x_init = base_params.copy()
            if trial > 0 and chosen_spread > 0:
                x_init = x_init + rng.normal(scale=chosen_spread, size=2 * chosen_p)

            if use_spsa:
                sol = self._optimize_spsa(objective_fn, x_init, chosen_maxiter, rng)
                total_iterations += sol.nit
            else:
                jac = None
                if grad_method_key == "shot_based":
                    jac = lambda x, *args: self._gradient(
                        x, circuit, chosen_p, h, J, chosen_shots,
                    )
                elif grad_method_key == "estimator":
                    jac = lambda x, *args: self._gradient_estimator(
                        x,  circuit_no_measure, chosen_p, h, J, chosen_shots,
                        )
                # åˆ›å»ºè¿›åº¦æ¡
                # pbar = tqdm(total=chosen_maxiter, desc=f"Trial {trial+1}/{chosen_trials}", leave=False)
                current_iter = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹
                
                def callback(xk):
                    current_iter[0] += 1
                    # pbar.update(1)
                    # è®¡ç®—å½“å‰ç›®æ ‡å‡½æ•°å€¼ç”¨äºæ˜¾ç¤º
                    # current_val = objective_fn(xk)
                    # pbar.set_postfix({"obj": f"{current_val:.4e}"})
                
                minimize_kwargs = {
                    "x0": x_init,
                    "method": chosen_algorithm,
                    "options": {"maxiter": chosen_maxiter},# "disp": True, 'maxfev': 300, 'final_tr_radius': 1e-5},
                    "tol": 1e-4,
                    "bounds": bounds,
                    "callback": callback,
                    "jac": True
                }
                # if jac is not None:
                    # minimize_kwargs["jac"] = jac

                # sol = minimize(objective_fn, **minimize_kwargs)
                sol = minimize(objective_fn_with_grad, **minimize_kwargs)
                # pbar.close()
                total_iterations += sol.nit

            if np.isfinite(sol.fun) and sol.fun < best_value:
                best_value = sol.fun
                best_solution = sol

        if "iterations" in metadata:
             metadata["iterations"] += total_iterations
        else:
             metadata["iterations"] = total_iterations

        if best_solution is None:
            return None

        # --- ç»“æœè§£æ ---
        best_params = best_solution.x
        betas = best_params[:chosen_p]
        gammas = best_params[chosen_p:]
        if self.use_history:
            self.history={
                "betas": betas,
                "gammas": gammas,
                "objective_value": best_value
            }
        bind_dict = self._build_bind_dict(circuit, chosen_p, betas, gammas)
        counts = self._run_counts(circuit, bind_dict, chosen_shots)
        
        if not counts:
            return None

        # åŒæ ·ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•å¯»æ‰¾æœ€ä¼˜è§£
        bitstrings = list(counts.keys())
        char_matrix = np.array([list(s) for s in bitstrings])
        spins_matrix = np.ones(char_matrix.shape, dtype=float)
        spins_matrix[char_matrix == '1'] = -1.0
        spins_matrix = np.flip(spins_matrix, axis=1) # è®°å¾—ç¿»è½¬
        
        # æ‰¹é‡è®¡ç®—èƒ½é‡
        term1 = spins_matrix @ h
        term2 = np.sum((spins_matrix @ J) * spins_matrix, axis=1)
        energies = term1 + term2 + C # åŠ ä¸Šå¸¸æ•°é¡¹
        
        min_idx = np.argmin(energies)
        best_spins = spins_matrix[min_idx].astype(int)

        return self._spins_to_asset_counts(best_spins, n, x0)

    # --- æ–°å¢: Interp æ’å€¼æ ¸å¿ƒé€»è¾‘ ---
    def _interpolate_params(self, old_params: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨çº¿æ€§æ’å€¼å°†å‚æ•°ä» p å±‚æ‰©å±•åˆ° p+1 å±‚ (Interp Strategy)
        ä¿ç•™æ³¢å½¢å½¢çŠ¶ï¼Œå¹³æ»‘æ‰©å±•åˆ°æ›´æ·±çš„ç”µè·¯ã€‚
        """
        num_params = len(old_params)
        p_old = num_params // 2
        
        if p_old == 0:
            return self._initial_params(1, None, None)

        betas_old = old_params[:p_old]
        gammas_old = old_params[p_old:]

        p_new = p_old + 1
        
        # å®šä¹‰æ—§çš„æ—¶é—´è½´ [0, 1] å’Œæ–°çš„æ—¶é—´è½´
        # ä½¿ç”¨ä¸­å¿ƒç‚¹å¯¹é½æ•ˆæœé€šå¸¸æ›´å¥½: (i + 0.5) / p
        x_old = (np.arange(p_old) + 0.5) / p_old
        x_new = (np.arange(p_new) + 0.5) / p_new
        
        # çº¿æ€§æ’å€¼
        betas_new = np.interp(x_new, x_old, betas_old)
        gammas_new = np.interp(x_new, x_old, gammas_old)
        
        return np.concatenate([betas_new, gammas_new])

    # --- ä¿®æ”¹: åŠ å…¥ strategy å‚æ•°å¹¶æ”¯æŒé€å±‚å¾ªç¯ ---
    def _optimize_interp(
        self,
        mu: np.ndarray,
        prices: np.ndarray,
        sigma: np.ndarray,
        budget: float,
        x0: Optional[np.ndarray] = None,
        p: Optional[int] = None,
        shots: Optional[int] = None,
        n_trials: Optional[int] = None,
        maxiter: Optional[int] = None,
        initial_betas: Optional[Sequence[float]] = None,
        initial_gammas: Optional[Sequence[float]] = None,
        init_spread: Optional[float] = None,
        seed: Optional[int] = None,
        optimization_algorithm: Optional[str] = None,
        grad_method: Optional[str] = None,
        strategy: str = "interp",  # <--- æ–°å¢å‚æ•°: "standard" or "interp"
        **kwargs,
    ) -> Optional[np.ndarray]:
        n = len(mu)
        self.num_spins, self.bits_plus, self.bits_minus = self.compute_num_spins(n, x0)

        # 1. è®¡ç®— Ising/QUBO (è¿™éƒ¨åˆ†åªä¸é—®é¢˜æœ‰å…³ï¼Œä¸ p æ— å…³ï¼Œæ”¾åœ¨å¾ªç¯å¤–)
        Q, L, constant = self.qubo_factor(n, mu, sigma, prices, self.num_spins, budget, x0)
        h, J, C = self.get_ising_coeffs(Q, L, constant)
        h, J, C = normalize_ising_coeffs(h, J, C)
        
        # å‚æ•°è§£æ
        target_p = p if p is not None else self.p
        chosen_shots = shots if shots is not None else self.shots
        chosen_trials = n_trials if n_trials is not None else self.n_trials
        chosen_maxiter = maxiter if maxiter is not None else self.maxiter
        chosen_spread = init_spread if init_spread is not None else self.init_spread
        chosen_seed = seed if seed is not None else self.seed
        
        # ç¡®å®šç®—æ³•
        chosen_algorithm = (
            optimization_algorithm
            if optimization_algorithm is not None
            else self.optimization_algorithm
        )
        if not chosen_algorithm:
            chosen_algorithm = "COBYLA"
            
        chosen_grad_method = grad_method if grad_method is not None else self.grad_method
        grad_method_key = (chosen_grad_method or "").lower()
        method_key = chosen_algorithm.strip().upper()
        use_spsa = method_key == "SPSA"
        
        # --- ç­–ç•¥æ§åˆ¶é€»è¾‘ ---
        if strategy.lower() == "interp":
            print(f"ğŸš€ Starting Interp Strategy optimization up to p={target_p}...")
            p_schedule = range(1, target_p + 1)
        else:
            p_schedule = [target_p]

        best_global_solution = None
        best_global_value = float("inf")
        
        # å­˜å‚¨ä¸Šä¸€å±‚çš„æœ€ä¼˜å‚æ•°ç”¨äºæ’å€¼
        prev_layer_params = None

        # --- 2. é€å±‚å¾ªç¯ (Interp Loop) ---
        for current_p in p_schedule:
            if strategy.lower() == "interp":
                print(f"  > Optimizing Layer p={current_p}...")
            
            # 2.1 ç¡®å®šå½“å‰å±‚çš„åˆå§‹åŒ–å‚æ•°
            if current_p == 1:
                # ç¬¬ä¸€å±‚ä½¿ç”¨æ ‡å‡†åˆå§‹åŒ– (Random or Linear)
                base_params = self._initial_params(current_p, initial_betas, initial_gammas)
                # å¦‚æœæ˜¯ interp æ¨¡å¼ï¼Œç¬¬ä¸€å±‚é€šå¸¸ä¸éœ€è¦å¤ªå¤§ spreadï¼Œä¸»è¦é  optimize æ‰¾æ–¹å‘
                current_spread = chosen_spread 
            else:
                # åç»­å±‚ä½¿ç”¨æ’å€¼
                base_params = self._interpolate_params(prev_layer_params)
                # æ’å€¼åçš„ç‚¹é€šå¸¸å·²ç»å¾ˆå¥½ï¼Œspread å¯ä»¥è®¾å°ä¸€ç‚¹æˆ–è€…ä¸º0
                current_spread = chosen_spread * 0.5 

            # 2.2 æ„å»ºå½“å‰å±‚çš„ç”µè·¯
            circuit = self._build_circuit(current_p, h, J) 
            circuit_no_measure = self._build_circuit(current_p, h, J, measure=False)
            
            # Transpile
            circuit = transpile(circuit, self.backend)
            circuit_no_measure = transpile(circuit_no_measure, self.backend)
            
            # 2.3 å®šä¹‰ç›®æ ‡å‡½æ•° (ç»‘å®šå½“å‰çš„ current_p)
            obj_circuit = circuit_no_measure if grad_method_key == "estimator" else circuit
            
            objective_fn = lambda params: self._objective(
                params, obj_circuit, current_p, h, J, chosen_shots
            )
            
            objective_fn_with_grad = lambda params: self._compute_val_and_grad(
                params, obj_circuit, current_p, h, J, chosen_shots
            )

            bounds = [(0, 2*np.pi)] * (2 * current_p)
            rng = np.random.default_rng(chosen_seed)
            
            # å½“å‰å±‚æœ€å¥½çš„ç»“æœ
            layer_best_sol = None
            layer_best_val = float("inf")

            # 2.4 å¤šæ¬¡ Trial ä¼˜åŒ– (é˜²æ­¢å•å±‚é™·å…¥å±€éƒ¨æœ€ä¼˜)
            # å¯¹äº Interpï¼Œé€šå¸¸ trials å¯ä»¥è®¾å°‘ä¸€ç‚¹(æ¯”å¦‚1-3æ¬¡)ï¼Œå› ä¸ºåˆå€¼å·²ç»å¾ˆå¥½
            current_trials = chosen_trials if current_p == 1 or strategy != "interp" else max(1, chosen_trials // 2)

            for trial in range(current_trials):
                x_init = base_params.copy()
                # åªæœ‰å½“ä¸æ˜¯ç¬¬ä¸€å±‚ç›´æ¥æ’å€¼å¾—åˆ°çš„ç»“æœï¼Œä¸”éœ€è¦æ‰°åŠ¨æ—¶æ‰åŠ å™ªå£°
                if (trial > 0 or (current_p == 1 and strategy != "interp")) and current_spread > 0:
                    x_init = x_init + rng.normal(scale=current_spread, size=2 * current_p)
                
                # æ‰§è¡Œä¼˜åŒ–
                sol = None
                if use_spsa:
                    sol = self._optimize_spsa(objective_fn, x_init, chosen_maxiter, rng)
                else:
                    minimize_kwargs = {
                        "x0": x_init,
                        "method": chosen_algorithm,
                        "options": {"maxiter": chosen_maxiter},
                        "tol": 1e-4,
                        "bounds": bounds,
                        "jac": True if grad_method_key == "estimator" else False 
                    }
                    
                    if grad_method_key == "estimator":
                         sol = minimize(objective_fn_with_grad, **minimize_kwargs)
                    else:
                        # Shot-based gradient logic (omitted for brevity, same as before)
                         # ... existing gradient logic if needed ...
                         pass 

                if sol is not None and np.isfinite(sol.fun) and sol.fun < layer_best_val:
                    layer_best_val = sol.fun
                    layer_best_sol = sol

            # 2.5 è®°å½•å½“å‰å±‚ç»“æœ
            if layer_best_sol is not None:
                prev_layer_params = layer_best_sol.x
                # å¦‚æœæ˜¯æœ€åä¸€å±‚ï¼Œæˆ–è€…é interp æ¨¡å¼ï¼Œæ›´æ–°å…¨å±€æœ€ä¼˜
                if current_p == target_p:
                    best_global_solution = layer_best_sol
                    best_global_value = layer_best_val
            else:
                print(f"âš ï¸ Warning: Optimization failed at p={current_p}")
                break

        # --- 3. æœ€ç»ˆç»“æœå¤„ç† (ä½¿ç”¨ best_global_solution) ---
        if best_global_solution is None:
            return None

        best_params = best_global_solution.x
        
        # ... (åç»­ç”¨äºæœ€åè¾“å‡ºèµ„äº§é…ç½®çš„ä»£ç ä¿æŒä¸å˜) ...
        # æ³¨æ„: ä¸‹é¢çš„ circuit éœ€è¦ç”¨ target_p é‡æ–°æ„å»ºä¸€æ¬¡ç”¨äºæœ€åé‡‡æ ·ï¼Œ
        # æˆ–è€…ç›´æ¥ä½¿ç”¨å¾ªç¯æœ€åä¸€æ¬¡çš„ circuit (å¦‚æœåœ¨å¾ªç¯å¤–éœ€è¦å°å¿ƒä½œç”¨åŸŸ)
        
        final_circuit = self._build_circuit(target_p, h, J)
        final_circuit = transpile(final_circuit, self.backend)
        
        final_betas = best_params[:target_p]
        final_gammas = best_params[target_p:]
        
        bind_dict = self._build_bind_dict(final_circuit, target_p, final_betas, final_gammas)
        counts = self._run_counts(final_circuit, bind_dict, chosen_shots)
        
        if not counts:
            return None
            
        # å‘é‡åŒ–å¯»æ‰¾æœ€ä¼˜ Bitstring
        bitstrings = list(counts.keys())
        char_matrix = np.array([list(s) for s in bitstrings])
        spins_matrix = np.ones(char_matrix.shape, dtype=float)
        spins_matrix[char_matrix == '1'] = -1.0
        spins_matrix = np.flip(spins_matrix, axis=1) 
        
        term1 = spins_matrix @ h
        term2 = np.sum((spins_matrix @ J) * spins_matrix, axis=1)
        energies = term1 + term2 + C
        
        min_idx = np.argmin(energies)
        best_spins = spins_matrix[min_idx].astype(int)

        return self._spins_to_asset_counts(best_spins, n, x0)